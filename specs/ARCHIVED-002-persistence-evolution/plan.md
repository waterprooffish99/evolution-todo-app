# Implementation Plan: Persistence Evolution (Phase II)

**Branch**: `002-persistence-evolution` | **Date**: 2026-01-01 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-persistence-evolution/spec.md`

**Note**: This plan was generated by the `/sp.plan` command following the SDD-RI methodology.

## Summary

Phase II adds JSON-based persistent storage to the Phase I in-memory todo application. All task state changes (Create, Update, Delete, Toggle) will automatically persist to `data/todo_data.json` using atomic write operations. The persistence layer wraps Phase I skills without modifying them, maintaining full backward compatibility. Error handling includes corruption detection with backup/recovery options.

**Technical Approach**: Write-then-rename atomic writes, wrapper pattern for transparent persistence, explicit schema versioning for future migrations.

## Technical Context

**Language/Version**: Python 3.13+ (Phase I requirement, unchanged)
**Primary Dependencies**: Python Standard Library only (json, os, pathlib, datetime modules)
**Storage**: Local JSON file (`data/todo_data.json`)
**Testing**: pytest (Phase I requirement, unchanged)
**Target Platform**: Linux/macOS/Windows with Python 3.13+
**Project Type**: Single (console CLI application)
**Performance Goals**: Load < 1s for 1,000 tasks; Save < 100ms per operation
**Constraints**: < 100MB memory (constitution), no external dependencies, backward compatible with Phase I
**Scale/Scope**: Comfortable up to 10,000 tasks; warning threshold at 10,000+

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### Phase I Principles (Must Maintain)

✅ **Spec-Driven First**: Spec created before implementation (this document)
✅ **Reusable Intelligence**: Phase I skills remain unchanged, persistence is separate layer
✅ **Human-Readable Design**: JSON format, clear error messages, user recovery options
✅ **Clean Phase Boundaries**: No AI/web/database logic, only local file storage

### Amendment I: Persistence (Must Comply)

✅ **All state changes persist immediately**: Save after every mutation (Add/Update/Delete/Toggle)
✅ **Data storage in data/todo_data.json**: Defined in research.md and data-model.md
✅ **Auto-loading on startup**: Implemented in `initialize_persistence()`
✅ **Error handling for corruption**: Backup + recovery options in `handle_corrupted_file()`
✅ **Phase I skills remain source of truth**: Wrapper pattern, no skill modifications

### Technical Guardrails

✅ **Language**: Python 3.13+ (unchanged)
✅ **Runtime**: Console/CLI only (unchanged)
✅ **Persistence**: Now file-based (JSON), previously in-memory
✅ **Architecture**: Menu-driven CLI + persistence layer wrapper
✅ **No external services or databases**: JSON file is local only

### Violations

**None.** This implementation complies with all constitution principles and Amendment I requirements.

## Project Structure

### Documentation (this feature)

```text
specs/002-persistence-evolution/
├── spec.md              # Feature specification (user stories, requirements)
├── plan.md              # This file (/sp.plan command output)
├── research.md          # Phase 0 output (technical decisions, alternatives)
├── data-model.md        # Phase 1 output (Task entity, JSON schema)
├── quickstart.md        # Phase 1 output (implementation guide)
├── contracts/           # Phase 1 output (API contracts)
│   └── persistence-api.md
└── tasks.md             # Phase 2 output (/sp.tasks command - NOT YET CREATED)
```

### Source Code (repository root)

**Structure**: Single project (console CLI application)

```text
src/
├── skills.py            # Phase I skills (AddTask, UpdateTask, etc.) - UNCHANGED
├── persistence.py       # Phase II NEW - Persistence layer (load/save)
├── cli.py               # CLI interface (menu-driven) - MODIFIED (add save calls)
└── main.py              # Application entry point - MODIFIED (call initialize_persistence)

tests/
├── test_skills.py                   # Phase I tests - UNCHANGED (must still pass)
├── test_persistence.py              # Phase II NEW - Persistence unit tests
├── test_persistence_integration.py  # Phase II NEW - Integration tests
└── conftest.py                      # pytest fixtures (shared across tests)

data/
├── .gitkeep             # Track directory in git
└── todo_data.json       # User data (gitignored, created at runtime)

.gitignore               # Exclude data/ directory (except .gitkeep)
```

**Structure Decision**:

We continue with the single project structure from Phase I. The persistence layer is added as a new module (`src/persistence.py`) that wraps Phase I skills. The CLI layer (`src/cli.py` and `src/main.py`) is modified to call persistence functions, but Phase I skills (`src/skills.py`) remain completely unchanged.

**Key Files**:
- **NEW**: `src/persistence.py` - All persistence logic (load, save, error handling)
- **MODIFIED**: `src/main.py` - Add `initialize_persistence()` call at startup
- **MODIFIED**: `src/cli.py` - Add `save_tasks()` calls after mutations
- **UNCHANGED**: `src/skills.py` - Phase I business logic remains untouched

**Data Directory**:
- `data/` directory stores user JSON files
- Excluded from git (via `.gitignore`) except `.gitkeep`
- Created automatically on first run

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**No violations detected.** This implementation fully complies with:
- Phase I principles (spec-driven, reusable skills, human-readable)
- Amendment I requirements (immediate persistence, error handling)
- Technical guardrails (Python only, console CLI, no external services)

## Implementation Architecture

### Persistence Layer Design

**Pattern**: Wrapper around Phase I skills

```
┌─────────────────────────────────────┐
│         User Interface (CLI)        │
│  - Menu display                     │
│  - Input validation                 │
│  - Result formatting                │
└──────────────┬──────────────────────┘
               │
               │ (1) Call skill
               │ (2) Call save (if mutation)
               ▼
┌──────────────────────────────────────┐
│      Persistence Layer (NEW)         │
│  ┌────────────────────────────────┐  │
│  │ initialize_persistence()       │  │ ← Startup
│  │  - Load JSON from file         │  │
│  │  - Populate in-memory state    │  │
│  │  - Set next_task_id            │  │
│  └────────────────────────────────┘  │
│  ┌────────────────────────────────┐  │
│  │ save_tasks()                   │  │ ← After mutations
│  │  - Serialize to JSON           │  │
│  │  - Atomic write (tmp + rename) │  │
│  └────────────────────────────────┘  │
└──────────────┬──────────────────────┘
               │
               │ Calls Phase I skills
               ▼
┌──────────────────────────────────────┐
│    Phase I Skills (UNCHANGED)        │
│  - AddTask(title, desc)              │
│  - GetTasks()                        │
│  - UpdateTask(id, title, desc)       │
│  - DeleteTask(id)                    │
│  - ToggleTaskStatus(id)              │
│                                      │
│  Operates on in-memory:              │
│    tasks = []                        │
│    next_task_id = 1                  │
└──────────────────────────────────────┘
```

### Data Flow

**Application Startup**:
1. User runs `python3 src/main.py`
2. `main.py` calls `initialize_persistence()`
3. Persistence layer loads `data/todo_data.json`
4. Tasks populate in-memory `tasks` list
5. `next_task_id` set to max(task IDs) + 1
6. CLI menu displays

**Mutation Operation** (e.g., Add Task):
1. User selects "Add Task" from menu
2. CLI collects input (title, description)
3. CLI calls `AddTask(title, description)` ← Phase I skill
4. Phase I skill adds task to in-memory `tasks` list
5. Phase I skill returns new task
6. CLI calls `save_tasks()` ← Persistence layer
7. Persistence serializes `tasks` to JSON
8. Persistence writes to `data/todo_data.json.tmp`
9. Persistence renames `.tmp` to `todo_data.json` (atomic)
10. CLI displays success message

**Read Operation** (e.g., View Tasks):
1. User selects "View Tasks" from menu
2. CLI calls `GetTasks()` ← Phase I skill
3. Phase I skill returns in-memory `tasks` list
4. CLI formats and displays tasks
5. **No save needed** (read-only)

### Error Handling Strategy

**Corruption Detection**:
- On startup, `load_tasks()` catches `json.JSONDecodeError`
- Backup corrupted file: `todo_data.json.corrupt.YYYY-MM-DDTHH-MM-SS`
- Prompt user: (1) Create fresh file or (2) Exit to fix manually

**Permission Errors**:
- Catch `PermissionError` on read/write
- Display user-friendly message with fix instructions
- Exit gracefully (cannot continue without file access)

**Disk Full**:
- Catch `OSError` (errno 28) on write
- Display error, keep old file intact (atomic write failed)
- Instruct user to free space

**Missing File** (first run):
- `FileNotFoundError` on load → Expected
- Create `data/` directory and empty JSON file
- Continue with 0 tasks

### Atomic Write Implementation

**Strategy**: Write-then-rename

```python
def ensure_atomic_write(data, filepath):
    """
    Atomic file write to prevent corruption.

    Steps:
    1. Serialize data to JSON string
    2. Write to temporary file (filepath.tmp)
    3. Atomically rename temp to target (os.replace)

    Guarantees:
    - Target file is either fully updated or unchanged
    - No partial writes (crash during write leaves temp file)
    - No data loss (old file preserved until rename succeeds)
    """
    tmp_path = f"{filepath}.tmp"

    # Write to temp file
    with open(tmp_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    # Atomic rename (POSIX + Windows guarantee)
    os.replace(tmp_path, filepath)
```

**Why Atomic**: If crash occurs during write, temp file is corrupted but original file remains valid. Rename is atomic on all platforms.

### Schema Versioning

**Current Version**: 1.0

**JSON Structure**:
```json
{
  "version": "1.0",
  "tasks": [
    {"id": 1, "title": "Task 1", "description": "", "completed": false}
  ]
}
```

**Future Migration Path**:
- Load file, check `version` field
- If version < current: Run migration functions
- If version > current: Error (downgrade not supported)
- Migration example: Version 1.0 → 1.1 adds `created_at` field

## Testing Strategy

### Test Pyramid

**Unit Tests** (60% of tests):
- `test_persistence.py`: Test each persistence function in isolation
- Mock file I/O to test error paths (corruption, permissions)
- Fast, no real file operations

**Integration Tests** (30% of tests):
- `test_persistence_integration.py`: Test Phase I skills + persistence together
- Real file operations (use `tmp_path` fixture)
- Verify save/load round-trips

**Phase I Regression Tests** (10% of tests):
- Run existing `test_skills.py` unchanged
- Verify backward compatibility (all must pass)

### Key Test Scenarios

**Persistence Unit Tests**:
1. Initialize creates directory if missing
2. Initialize creates empty file on first run
3. Initialize loads existing tasks correctly
4. Save writes valid JSON to file
5. Save is atomic (uses temp file + rename)
6. Load handles corrupted JSON gracefully
7. Load backs up corrupted files with timestamp
8. Task ID continuity after restart

**Integration Tests**:
1. Add task → restart → task still exists
2. Update task → restart → changes persisted
3. Delete task → restart → task gone
4. Toggle status → restart → status persisted
5. Multiple operations → restart → all changes preserved

**Error Handling Tests**:
1. Corrupted JSON offers recovery options
2. Permission error displays helpful message
3. Disk full preserves old file
4. Missing directory is created automatically

### Coverage Targets

- Persistence module: > 90% coverage
- Overall project: > 85% coverage
- All Phase I tests: 100% pass rate (unchanged)

## Performance Targets

**Load Performance**:
- Target: < 1 second for 1,000 tasks
- Expected: ~10-50ms for typical use (< 100 tasks)
- Warning: > 5s indicates issue, investigate

**Save Performance**:
- Target: < 100ms per save
- Expected: ~5-20ms for typical task counts
- Warning: > 1s indicates issue (file system slow?)

**Memory Usage**:
- In-memory task list: ~100 bytes per task
- 10,000 tasks ≈ 1MB in memory (well under 100MB limit)
- Acceptable: JSON file + in-memory duplication during save

## Risk Mitigation

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Data corruption | Low | High | Atomic writes, backup on corruption |
| Phase I compatibility break | Low | High | No skill modifications, run all Phase I tests |
| Performance degradation | Low | Medium | Performance tests, warning at 10k tasks |
| User data loss | Very Low | High | Atomic writes guarantee + corruption backups |
| File permission issues | Medium | Medium | Clear error messages with fix instructions |

## Rollout Plan

**Phase II Deployment**:
1. Implement `src/persistence.py` following contracts
2. Run all unit tests (persistence + Phase I regression)
3. Manual testing: fresh start, restart persistence, corruption recovery
4. Integration tests: verify Phase I + persistence together
5. Performance validation: load/save time tests
6. Documentation: Update README if applicable
7. Merge to main, tag release `v0.2.0-persistence`

**Backward Compatibility**:
- Phase I users: No changes needed (persistence adds value, doesn't break)
- Phase I tests: Must pass 100% unchanged
- Phase I skills: Zero modifications to function signatures or behavior

## Success Criteria

Phase II is complete when:
- [ ] All Phase I tests pass without modification
- [ ] All Phase II persistence tests pass (unit + integration)
- [ ] Manual testing scenarios verified (fresh start, restart, corruption)
- [ ] Performance targets met (load < 1s, save < 100ms)
- [ ] Code coverage > 90% for persistence module
- [ ] Constitution compliance verified (no violations)
- [ ] Documentation complete (quickstart.md usable by developers)

## Next Steps

**After /sp.plan completes**:
1. Run `/sp.tasks` to generate testable implementation tasks
2. Run `/sp.implement` to execute tasks (or implement manually)
3. Verify all acceptance criteria from spec.md
4. Create pull request for review
5. Merge and tag release

**Future Phases** (Phase III ideas):
- Add timestamps (created_at, updated_at)
- Implement task search/filtering
- Add tags or categories
- Migrate to SQLite for performance
- Cloud synchronization
